Semi-XctNet: Volumetric images reconstruction network from a single projection image via semi-supervised learning 
ABSTRACT  
Deep learning networks have achieved remarkable progress in various tasks of medical imaging. Most of the recent success in computer vision highly depend on large amounts of carefully annotated data, whereas labelling is arduous, time-consuming and in need of expertise. In this paper, a semi-supervised learning method, Semi- XctNet, is proposed for volumetric images reconstruction from a single X-ray image. In our framework, the effect of regularization on pixel-level prediction is enhanced by introducing a transformation consistent strategy into the model. Furthermore, a multi-stage training strategy is designed to ameliorate the generalization performance of the teacher network. An assistant module is also introduced to improve the pixel quality of pseudo- labels, thereby further improving the reconstruction accuracy of the semi-supervised model. The semi-supervised method proposed in this paper has been extensively validated on the LIDC-IDRI lung cancer detection public data set. Quantitative results show that SSIM (structural similarity measurement) and PSNR (peak signal noise ratio) are 0.8384 and 28.7344 respectively. Compared with the state-of-the-arts, Semi-XctNet exhibits excellent reconstruction performance, thus demonstrating the effectiveness of our method on the task of volumetric images reconstruction network from a single X-ray image.   
1. Introduction 
In recent years, deep learning methods have been proven to have enormous potential in medical data processing [(\ensuremath{<}\ensuremath{>})2{\textendash}4]. Wang et al. [(\ensuremath{<}\ensuremath{>})5] point out that as artificial intelligence technology continues to develop, new breakthroughs will be made in the field of tomographic imaging. In addition, Sahiner et al. [(\ensuremath{<}\ensuremath{>})6] provide a summary of current research in medical radiography and indicate that combining deep learning model innovations will be a key research direction for the future [(\ensuremath{<}\ensuremath{>})7]. The deep-learning approaches avoid playing with the pixels, but instead focus on the driving data as well as the learning architectures. In terms of 3D construction, the construction from single image is an ill-posed problem and is almost unsolvable through traditional algorithms, nonetheless, this problem is already partially settled by various teams using deep learning methods. Shen et al. [(\ensuremath{<}\ensuremath{>})8]. achieved the reconstruction of CT volumetric images from 2D projections for the first time 
through deep learning. The substantial progress can be explained as that the learning mechanism takes the advantage of prior knowledge from data and succeeds in recovering the spatial information of the pixels from images, which is in analogy with the way doctors grasp anatomical information from radiographs. 
Different from natural images, large-scale data is not always available due to various reasons like privacy, patient volume, the database construction of hospital and so on. In addition, the annotation of medical image data is integral to supervised learning, which requires clinical experience and is time costly. In the process of clinical diagnosis, patients usually take X-ray images for preliminary investigation, and then CT scans are performed for further diagnosis, so that the amount of X-ray data is usually greater than CT data, which makes the data for volumetric construction a partially labeled dataset. To solve this problem, this paper proposes a method for reconstructing CT volumetric images from 2D projection images based on semi-supervised learning. This method can achieve the reconstruction tasks from a large number of unpaired 2D projection images and a small fraction of paired 2D pro-jection/CT volumetric image data. 
The semi-supervised reconstruction algorithm proposed in this paper includes three models, namely, a teacher model, an assistant model and a student model. The teacher model is used to generate pseudo-labels to train the teacher model, the assistant model is designed to enhance the details of pseudo-labels, while the student model is created for self- supervised training of volumetric image reconstruction. The main contributions of this paper are as follows.  
2. Related work 
Various significant research findings have been established in the field of image-based 3D reconstruction, which aim to infer the 3D structure of objects from single-view or multi-view 2D images. Nozawa et al. [(\ensuremath{<}\ensuremath{>})9] proposed a deep learning model for reconstructing 3D car shape from a single 2D sketch image. The model acts as a variational autoencoder deep neural network that takes a 2D sketch and generates a set of multi-view depth and mask images, forming a more efficient representation and can be efficiently fused to generate a 3D car shape. Feng et al. [(\ensuremath{<}\ensuremath{>})10]. proposed an efficient end-to-end deep learning framework for reconstructing the 3D structure of porous media, which could be trained by inputting 2D slices into a deep learning model, and the corresponding 3D structure could be reconstructed instantaneously. Fu et al. [(\ensuremath{<}\ensuremath{>})11] reviewed recent work on 3D structure reconstruction from a single image and introduced the encoder structure and training details for this task. 
Current approaches for volumetric data construction from single image rely on the large amount of paired data in order to obtain satisfactory reconstruction results. For medical images, labelling requires clinical prior knowledge, which includes both complex anatomical theories and practical experiences, and it also takes plenty of time. Semi- supervised learning aims to enhance the learning performance of the model by making full use of a large number of unlabeled samples under the guidance of a small number of sample labels, so as to avoid waste of data resources, and to solve the problem of poor generalization caused by few labeled data in supervised learning methods [(\ensuremath{<}\ensuremath{>})15]. 
Lee [(\ensuremath{<}\ensuremath{>})16] proposed the concept of Pseudo-label by taking the target class with the highest prediction probability of unlabeled samples as the real label. The algorithm proved that training with pseudo-labels can make the entropy of unlabeled data samples smaller, so that the classification and generalization performance can be improved. Laine et al. [(\ensuremath{<}\ensuremath{>})17] proposed a simple and effective method for training deep neural networks in a semi-supervised environment, in which only a small part of the training data were labeled. This method introduces self-awareness and forms a consistent prediction for unknown labels under different regularization and input enhancement conditions. For unknown labels, the prediction set can be regarded as a better predictor than the network output in the recent training period, so it can be used as a training target. Sohn et al. [(\ensuremath{<}\ensuremath{>})18] proposed a semi-supervised learning algorithm named FixMatch by combining two common self-supervised learning methods (consistency regularization and pseudo-labeling). State--of-the-art performance was achieved on supervised learning benchmarks. In the same year, Google released a self-supervised learning framework [(\ensuremath{<}\ensuremath{>})19], SimCLR. This paper is not only simple in method, but also deepens our understanding of self-supervised learning and contrastive learning. On this basis, the Google team proposed SimCLR V2 [(\ensuremath{<}\ensuremath{>})20] for application, which mainly carries out unsupervised training on a large number of unlabeled samples, fine-tuned through a small number of labels and distills knowledge on unlabeled data. In addition, there are many advanced research results in semi-supervised learning in the field of medical image analysis. Li et al. [(\ensuremath{<}\ensuremath{>})21] proposed a new semi-supervised method for medical image segmentation, in which the network is optimized by a weighted combination of common supervision loss only for labeled input and regularization loss of labeled and unlabeled data. Yu et al. [(\ensuremath{<}\ensuremath{>})22] proposed a novel uncertainty-aware semi-supervised framework for 3D MR left atrial image segmentation, which enables student models to gradually learn from meaningful and reliable targets by exploiting uncertainty information. Wang et al. [(\ensuremath{<}\ensuremath{>})23] constructed a 3D medical image detection framework named FocalMix, which performed extensive experiments on two widely used lung nodule detection datasets. Results showed that FocalMix achieved substantial improvements of up to 17.3\% over state-of-the-art supervised learning methods over 400 unlabeled CT scans. 
Most current deep learning-based image reconstruction tasks are based on supervised learning models, owing to data in the medical imaging field is often not available on a large scale, supervised learning for image reconstruction tasks is usually not well suited to drive clinical applications. From the above literature, it can be seen that semi- supervised learning has shown performance effects that can surpass supervised learning, so it is a feasible novel method to apply semi- supervised learning to the field of medical image reconstruction. 
Fig. 1. The Schematic diagram of training process for volumetric images reconstruction. The teacher model uses labeled data for supervised training and provides pseudo-labels for unlabeled data training; the teacher model is trained based on pseudo-labels fused by different data augmentation methods and fine-tuned in the labeled data set. 
Fig. 2. The main architecture of XctNet. The model contains X-ray feature extraction module, the volumetric images generation module and multi-scale feature fusion module. The feature extraction module and volumetric images generation module are connected using multi-scale feature fusion module. The input of the model is a single X-ray image. The feature extraction module can be used to extract 2D feature information and optimize features adaptively. The New Inception module used in the volumetric images generation module can obtain more detailed results. 
3. Methodology 
In this paper, we propose a self-supervised learning-based single X- ray image reconstruction algorithm, Semi-XctNet, which aims to address the current imbalance in medical imaging data by using a small amount of X-ray/CT paired data and a large amount of unlabeled X-ray data. The labeled input and unlabeled input are single X-ray 
image, ground truth Y \ensuremath{\in} R C{\texttimes}H{\texttimes}W is CT volumetric images. A small amount of labeled data will be input into the teacher model to perform supervised training. In addition, the framework introduces a super- resolution reconstruction network as an auxiliary module to obtain high-resolution prediction results to improve the reconstruction accuracy of the teacher model. On the other hand, semi-supervised learning based on consistent regularization has made significant progress in image classification [(\ensuremath{<}\ensuremath{>})24,(\ensuremath{<}\ensuremath{>})25]. Consequently, a learning strategy based on consistent regularization and pseudo-label is proposed for 
Main Architecture of X-ray feature extraction Module.  
self-supervised learning of unlabeled data. As can be seen in (\ensuremath{<}\ensuremath{>})Fig. 1, the corresponding augmented images from unlabeled data set are obtained through different data augmentation methods and the related volumetric images are obtained through the teacher model. According to the principle of consistent regulation, the generated volumetric images is used as pseudo-label to train the student model. Furthermore, this paper proposes a multi-stage training strategy to promote the robustness of pseudo-label by continuously improving the teacher model. 
Teacher/Student modelUsing the end-to-end network model for CT volumetric images reconstruction task will lose abundant information due to the randomness of extracting X-ray feature information during down sampling operation, resulting in blurring and other phenomena in CT volumetric images reconstruction. To solve this problem, we propose a new network model, XctNet [(\ensuremath{<}\ensuremath{>})26], by adding a series of improved methods on the basis of the baseline model. As can be seen in (\ensuremath{<}\ensuremath{>})Fig. 2, a multi-scale feature fusion module is added based on the baseline model to improve the fine-grained features of the image generated by the model. On the other hand, channel attention and spatial attention mechanism [(\ensuremath{<}\ensuremath{>})27,(\ensuremath{<}\ensuremath{>})28] are taken into XctNet model. The attention module for feedforward convolutional neural network will infer relevant attention attempts from two different dimensions of channel and space in turn, thus, the obtained attention map is multiplied by the corresponding input feature map to adaptively optimize the features. In addition, XctNet, as a lightweight network model, although many novel modules are added to improve the performance of the model, it will not increase the amount of calculation. On the contrary, it can greatly progress the reconstruction performance of the model. 
Attention-based SRCNN: Under normal circumstances, the use of end-to-end neural networks for vision-related tasks will cause certain pixel loss. For generating CT volumetric images from a single X-ray image, since the X-ray only has a small amount of spatial information relationship corresponding to the CT volumetric image, a lot of pixel information will be lost in the reconstruction process. In this paper, an attention mechanism is added to the main network structure of SRCNN [(\ensuremath{<}\ensuremath{>})29] to enhance the reconstruction accuracy of the model and use it as an assistant model to reconstruct the generated volume images. The network mainly contains three convolution modules. Among them, the number of input channels is 128 {\texttimes} 128 {\texttimes} 128 and the convolution kernel and padding layer parameters of each layer adopt different sizes through calculation to ensure that the final output is consistent with the size of the input. 
Algorithm 1. Semi-supervised learning for volumetric images reconstruction. 
To better generate medical reconstruction images, a loss function based on similarity measurement will be used in the self-supervised learning task. The ground truth YP provided for self-supervised learning is pseudo-labels generated by teacher model, Ypre represent volumetric images generated by teacher model. The optimization used in self-supervised learning process can be seen as Eq. (\ensuremath{<}\ensuremath{>})(1), among them, LGCC(Ypre, YP) is the similarity measurement function, which is used to evaluate the consistent regularization in the self-supervised training process and the \ensuremath{\lambda}\ensuremath{\Vert}w\ensuremath{\Vert}2 is the spatial norm regularization term, which is used to constrain the spatial smoothness of the generated volumetric image and improve the anti-interference ability of the model. 
(1) 
VoxelMorph [(\ensuremath{<}\ensuremath{>})32] summarized the similarity of images used to measure the image, using mean squared voxel difference as the evaluation metric for images that are susceptible to grayscale distribution and contrast and the ground truth used in the self-supervised learning process is pseudo-labels. The poor quality of the pseudo-labels at the beginning of training may adversely affect the training process. Consequently, this article uses global cross-correlation (GCC) as the similarity measure function to improve the robustness of the training process, as shown in Eq. (\ensuremath{<}\ensuremath{>})(2). 
(2) 
(3)  
In the supervised learning task, the teacher and assistant models will be trained and the teacher model will be fine-tuned. Therefore, the loss function of this part includes two parts: The loss function shown in Eq. (\ensuremath{<}\ensuremath{>})(4) used in the teacher/agnostic model is MSE (Mean Squared Error). The assistant model uses the Smooth L1 loss function for optimization iterations, as shown in Eq. (\ensuremath{<}\ensuremath{>})(5) and (6). 
(4)  
(5)  
(6) 
In summary, the core of the algorithm in this paper is to implement a semi-supervised learning-based CT volumetric image reconstruction task by combining GCC and an uncertainty loss function. On the other hand, a multi-stage training strategy is proposed in this paper, which can obtain more accurate generation results through multiple rounds of training, thus helping doctors to perform more accurate preoperative or intraoperative planning tasks in practical clinical applications. 
4. Experimental design 
In order to evaluate the performance of the model, the predicted reconstruction results from the Semi-XctNet model are evaluated on the test set. This paper uses four evaluation functions for model evaluation, namely: MSE (mean squared error), MAE (mean absolute error), SSIM (structural similarity measurement) and PSNR (peak signal noise ratio). MSE and MAE are used to evaluate the deviation between the predicted reconstruction result and the target value. The image evaluation metric SSIM, incorporating the information of luminance, contrast and structures, is used to evaluate the degree of similarity between images. The commonly used PSNR is applied to evaluate the quality of our reconstructed volumetric images. Generally, reconstructed volumetric images with better structure and higher resolution will have higher SSIM and 
Fig. 3. Volumetric images comparison of ReconNet, XctNet and Semi-XctNet on LIDC-IDRI data set. (a){\textendash}(d) represent the ground truth of a randomly selected 2D projection and the corresponding reconstruction results from different network, respectively. 
PSNR values. 
The model proposed in this paper are trained using Pytorch on a device with three NVIDIA Tesla V100 graphic processing units. Firstly, the baseline model is trained in the labeled data set and then the model is applied as the first iteration of teacher model to provide pseudo-labels for teacher model training. Secondly, an adaptive learning rate is adopted to adjust the learning rate during the training process according to the training situation of the network during the training process. Each round of training iterates 32 epochs, for a total of four rounds of training. Those models obtained in the three rounds is named as ResXct (baseline model), CBAM/ECAXct and XctNet. 
5. Results and discussion 
As shown in (\ensuremath{<}\ensuremath{>})Fig. 3, the performance of different models is shown in the test set. The HU (Hounsfiled Unit) value reflects the degree of tissue absorption of X-rays. Values within different ranges can represent different organs. Since our algorithm reconstructs the entire thoracic data, in order to better visualize the reconstruction effect, we adaptively display the reconstruction effect according to the HU value of the bony area. (\ensuremath{<}\ensuremath{>})Fig. 3 (a) reveals the ground truth of a 2D projection randomly selected from the test set and the visualization results of 3D bony areas generated for the convenience of observing the reconstruction effect. (\ensuremath{<}\ensuremath{>})Fig. 3 (b){\textendash}(c) respectively represent the volumetric images and 3D bone region visualization results obtained based on the supervised learning model. It is worth noting that, for the convenience of comparison, the supervised learning dataset and semi-supervised dataset on which the models presented are of the same order of magnitude. The number of slices shown in (\ensuremath{<}\ensuremath{>})Fig. 3 are 5, 25, 45, 65 and 85 respectively. It can be seen that the results reconstructed by XctNet network model are more accurate. (\ensuremath{<}\ensuremath{>})Fig. 3 (d) shows the volumetric images and 3D visualization of bony regions based on the semi-supervised learning strategy proposed in this paper. From the reconstruction results, we can see that the details of the reconstruction results from the Semi-XctNet model are richer than 
ReconNet [(\ensuremath{<}\ensuremath{>})8]. In order to better show the superiority of the reconstruction results of Semi-XctNet, four evaluation functions have adopted to verify the reconstruction results on the test set. Among them, the evaluation method we use is to evaluate each test set data which contain 128 
The Reconstruction Results Based on Semi-supervised Learning are Evaluated on the Verification Set.   
This paper mainly discusses how to solve the problem of difficult labeling of current medical data from the training method of semi- supervised learning. To achieve our expected results, a series of strategies are adopted to improve the reconstruction accuracy of the model. 
Multi-stage Semi-Supervised Learning: Pseudo-label is the main method used in this paper to guide model training on unlabeled data. Therefore, the accuracy of pseudo-label will largely determine the reconstruction quality of semi-supervised learning. In this paper, a multi-stage semi-supervised learning strategy is designed to endow semi-supervised learning with better performance by constantly 
Multi-stage semi-supervised learning training results.  
Fig. 4. Model performance of semi-supervised learning with different numbers of labeled data. The red part represents the performance of the model based on semi-supervised learning, and the black part represents the performance of the model based on supervised learning. 
Fig. 5. Validation results of appending assistant modules. The degree of change in image entropy is closely related to the content and gray value of the image. It can be seen that the richer the content of the sliced image, the higher the image information entropy, that is, the color of the entropy map tends to be warmer. 
changing the teacher network model. The effectiveness of this strategy is verified as shown in (\ensuremath{<}\ensuremath{>})Table 4. First, the baseline model is adopted to perform pre-training on the labeled dataset in the first stage. Second, the pre-trained model is used from the first stage as a teacher network to guide the training of the CBAM/ECAXct model in the second stage. This training strategy is also adopted in the subsequent rounds of training, and our final training model, Semi-XctNet, can be obtained. From the evaluation results in (\ensuremath{<}\ensuremath{>})Table 4, the reconstructed model is gradually increasing with the increase of the number of iterations. Therefore, it can be proved that the semi-supervised learning method based on the multi-stage training strategy can effectively improve the reconstruction performance of the model. 
The performance of the supervised learning-based model tends to increase as the amount of data increases. This phenomenon also demonstrates that a semi-supervised learning-based model for volumetric data reconstruction can achieve satisfactory results with only a small amount of annotated data. It is worth noting that this result is not only applicable to the reconstruction task in this paper, but also to other 
Fig. 6. Visualization of volumetric image reconstruction results based on 2D projection. (a){\textendash}(b) are the 3D visualization results of the Semi-XctNet model combined with the assistant module and the Semi-XctNet model without the assistant module on three randomly selected volumetric data, respectively. 
medical clinical applications where it is difficult to annotate the data. Availability of Assistant modules: To reduce the pixel loss caused by using the end-to-end neural network model for the volumetric image reconstruction task. An assistant module based on super-resolution reconstruction technique is used to enhance the image quality of pseudo-label, thereby improving the reconstruction effect based on semi-supervised learning. As shown in (\ensuremath{<}\ensuremath{>})Fig. 5, we randomly selected an example from the test set and showed some slice image data generated by the Semi-XctNet model with or without assistant module. The numbers of these slice data are 7, 43, 67, 91 and 111 respectively. From the heat map of the volumetric images, the model combined with the assistant module has a clearer division of image details. The volume data reconstructed from the network contains 128 slice data. From the extracted slices, the reconstruction quality of the whole volume data can be observed. As can be seen from (\ensuremath{<}\ensuremath{>})Fig. 5 (a){\textendash}(b), the overall reconstruction quality of volumetric data can be further improved in combination with the assistant module. 
Furthermore, in order to verify the specificity and sensitivity of the Semi-XctNet with assistant model, we randomly selected three groups of test samples and performed 3D visualization of their reconstruction results, which are shown in (\ensuremath{<}\ensuremath{>})Fig. 6. From the three sets of reconstruction results, more detailed information can be reconstructed by combining the assistant module. Specifically, the network model combined with the assistant module allows a more accurate reconstruction of the bony regions and each region (thoracic vertebrae, ribs, etc.) can also be well observed from the visualization results. Thus, it can be demonstrated that the combination of the assistant modules can greatly improve the specificity and sensitivity of the model. 
The effectiveness of the semi-XctNet model can be verified by the various arguments mentioned above. From the performance comparison of supervised and semi-supervised learning, it can be found that semi- supervised learning has the potential to meet or even exceed the performance of supervised learning. In addition, we propose an auxiliary module to promote the accuracy of pseudo-labels, and the results are obvious from the comparison of model reconstruction performance with or without the assistant module. However, this dataset used in this paper obtained from different sources and the data format is not highly uniform. In addition, this data has only raw CT volume data and no clinical counterpart of X-ray data. Using the network model trained in this paper for real clinical applications may lead to poor generalization performance, which is one of the limitations of this paper. However, this limitation is caused by the data and is not limited by the network model proposed in this paper. Later, we will consider collecting experimental data from clinical pairs for in-depth study from a clinical perspective, or combining image style transfer algorithms to transfer features from X- rays to 2D projection images to generate the corresponding volume data. 
6. Conclusion 
In this paper, a novel and effective semi-supervised learning algorithm is proposed for the task of reconstructing volumetric CT images from a single X-ray image. The whole framework adopts the teacher- assistant-student scheme for training and optimizes the supervised loss and self-supervised loss by combining the image similarity and uncertainty factor. To further enhance the robustness of pseudo-labels, a multi-stage training strategy is proposed to ameliorate the performance of the teacher network. On the other hand, an assistant module is added in this paper to increase the accuracy of pseudo-labels, so that the student model can be guided to generate more accurate reconstructed images. The effectiveness of our method is demonstrated by comprehensive experimental analysis on public datasets. Furthermore, our proposed semi-supervised learning reconstruction algorithm, as a general algorithm, can be applied to other semi-supervised medical image analysis tasks. 
Declaration of competing interest 
The authors declare no competing interest. 
Acknowledgment 
This work was supported in part by National Natural Science Foundation of China (Grant No. 62003330, No.62050410349), Shenzhen Fundamental Research Funds (Grant No. JCYJ20220818101608019 No.JCYJ20190807170407391), Natural Science Foundation of Guang-dong Province(Grant No. 2019A1515011699) and Guangdong-Hong Kong-Macao Joint Laboratory of Human-Machine Intelligence-Synergy Systems, Shenzhen Institute of Advanced Technology. 
References 